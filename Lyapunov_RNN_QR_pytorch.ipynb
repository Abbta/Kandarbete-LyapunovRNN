{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import RNN, GRU, LSTM\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneStep(*params, model): \n",
    "    #Params is a tuple including h, x, and c (if LSTM)\n",
    "    l = len(params)\n",
    "    if l < 2:\n",
    "        print('Params must be a tuple containing at least (x_t, h_t)')\n",
    "        return None\n",
    "    elif l>2:\n",
    "        states = (params[1], params[2])\n",
    "        return model(params[0], states)\n",
    "    else:\n",
    "        return model(*params)\n",
    "\n",
    "def oneStepVarQR(J, Q):\n",
    "    Z = torch.matmul(torch.transpose(J, 1, 2), Q) #Linear extrapolation of the network in many directions\n",
    "    q, r = torch.qr(Z, some = True) #QR decomposition of new directions\n",
    "    s = torch.diag_embed(torch.sign(torch.diagonal(r, dim1 = 1, dim2 = 2)))#extract sign of each leading r value\n",
    "    return torch.matmul(q, s), torch.diagonal(torch.matmul(s, r), dim1 = 1, dim2 = 2) #return positive r values and corresponding vectors\n",
    "\n",
    "def calc_LEs_an(*params, model, k_LE=100000, rec_layer= 0, kappa = 10, diff= 10, warmup = 10, T_ons = 1):\n",
    "    cuda = next(model.parameters()).is_cuda\n",
    "    if cuda:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    bias = model.rnn_layer.bias\n",
    "    x_in = params[0].to(device)\n",
    "    x_in.requires_grad_(False)\n",
    "    hc = params[1]\n",
    "    h0 = hc.to(device)\n",
    "    h0.requires_grad_(False)\n",
    "\n",
    "    num_layers, batch_size, hidden_size = h0.shape\n",
    "    _, feed_seq, input_size = x_in.shape\n",
    "    L = num_layers*hidden_size\n",
    "        \n",
    "    k_LE = max(min(L, k_LE), 1)\n",
    "    Q = torch.reshape(torch.eye(L), (1, L, L)).repeat(batch_size, 1, 1).to(device)\n",
    "    Q = Q[:, :, :k_LE] #Choose how many exponents to track\n",
    "\n",
    "    ht = h0\n",
    "    states = (ht, ) #make tuple for easier generalization\n",
    "    rvals = torch.ones(batch_size, feed_seq, k_LE).to(device) #storage\n",
    "    #qvect = torch.zeros(batch_size, feed_seq, L, k_LE) #storage\n",
    "    t = 0\n",
    "\n",
    "\n",
    "    t_QR = t\n",
    "    for xt in tqdm(x_in.transpose(0,1)):\n",
    "        if (t - t_QR) >= T_ons or t==0 or t == feed_seq:\n",
    "            QR = True\n",
    "        else: \n",
    "            QR = False\n",
    "        xt = torch.unsqueeze(xt, 1) #select t-th element in the fed sequence\n",
    "        states = (ht, )\n",
    "        \n",
    "        if rec_layer=='rnn':\n",
    "            J = rnn_jac(model.rnn_layer.all_weights, ht, xt, bias = bias)\n",
    "        else:\n",
    "            print(\"error, rec_layer is not rnn\")\n",
    "            J = None\n",
    "        \n",
    "        _, states = oneStep(xt, *states, model=model)\n",
    "        if QR:\n",
    "            Q, r = oneStepVarQR(J, Q)\n",
    "            t_QR = t\n",
    "            \n",
    "        else:\n",
    "            Q = torch.matmul(torch.transpose(J, 1, 2), Q)\n",
    "            r = torch.ones((batch_size, hidden_size))\n",
    "        ht = states\n",
    "        rvals[:, t, :] = r\n",
    "        #qvect[:, t, :, :] = Q\n",
    "\n",
    "        t = t+1\n",
    "    LEs = torch.sum(torch.log2(rvals.detach()), dim = 1)/feed_seq\n",
    "    #     print(torch.log2(rvals.detach()).shape)\n",
    "    return LEs, rvals#, qvect\n",
    "    \n",
    "def rnn_jac(params_array, h, x, bias):\n",
    "    if bias:\n",
    "        W, U, b_i, b_h = param_split(params_array, bias)\n",
    "    else:\n",
    "        W, U = param_split(params_array, bias)\n",
    "    device = get_device(h)\n",
    "    num_layers, batch_size, hidden_size = h.shape\n",
    "    input_shape = x.shape[-1]\n",
    "    h_in = h.transpose(1,2).detach()\n",
    "    x_in = [x.squeeze(dim=1).t()]#input_shape, batch_size)]\n",
    "    if bias:\n",
    "        b = [b1 + b2 for (b1,b2) in zip(b_i, b_h)]\n",
    "    else:\n",
    "        b = [torch.zeros(W_i.shape[0],).to(device) for W_i in W]\n",
    "    J = torch.zeros(batch_size, num_layers*hidden_size, num_layers*hidden_size).to(device)\n",
    "    y = []\n",
    "    h_out = []\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        if layer>0:\n",
    "            x_l = h_out[layer-1]\n",
    "            x_in.append(x_l)\n",
    "        y.append((W[layer]@x_in[layer] + U[layer]@h_in[layer] + b[layer].repeat(batch_size,1).t()).t())\n",
    "        h_out.append(torch.tanh(y[layer]).t())\n",
    "        J_h = sech(y[layer])**2@U[layer]\n",
    "        J[:, layer*hidden_size:(layer+1)*hidden_size, layer*hidden_size:(layer+1)*hidden_size] = J_h\n",
    "        \n",
    "        if layer>0:\n",
    "            J_xt = sech(y[layer])**2@W[layer]\n",
    "            for l in range(layer, 0, -1):\n",
    "                J[:, layer*hidden_size:(layer+1)*hidden_size, (l-1)*hidden_size:l*hidden_size] = J_xt@J[:, (layer-1)*hidden_size:(layer)*hidden_size, (l-1)*hidden_size:l*hidden_size]\n",
    "    return J\n",
    "        \n",
    "    \n",
    "    \n",
    "def param_split(model_params, bias):\n",
    "#   model_params should be tuple of the form (W_i, W_h, b_i, b_h)\n",
    "    hidden_size =int(model_params[0][0].shape[0])\n",
    "    layers = len(model_params)\n",
    "    W = []\n",
    "    U = []\n",
    "    b_i = []\n",
    "    b_h = []\n",
    "    if bias:\n",
    "        param_list = (W, U, b_i, b_h)\n",
    "    else:\n",
    "        param_list = (W, U)\n",
    "    grouped = []\n",
    "    for idx, param in enumerate(param_list):\n",
    "        for layer in range(layers):\n",
    "#             if len(param.shape) == 1:\n",
    "#                 param = param.squeeze(dim=1)\n",
    "            param.append(model_params[layer][idx].detach())            \n",
    "        grouped.append(param)\n",
    "    return grouped\n",
    "\t\n",
    "## Define Math Functions\n",
    "def get_device(X):\n",
    "    if X.is_cuda:\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def sig(X):\n",
    "    device = get_device(X)\n",
    "    return 1/(1+torch.exp(-X))\n",
    "def sigmoid(X):\n",
    "    device = get_device(X)\n",
    "    return torch.diag_embed(1/(1+torch.exp(-X)))\n",
    "def sigmoid_p(X):\n",
    "    device = get_device(X)\n",
    "    ones = torch.ones_like(X)\n",
    "    return torch.diag_embed(sig(X)*(ones-sig(X)))\n",
    "def sech(X):\n",
    "    device = get_device(X)\n",
    "    return torch.diag_embed(1/(torch.cosh(X)))\n",
    "def tanh(X):\n",
    "    device = get_device(X)\n",
    "    return torch.diag_embed(torch.tanh(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
