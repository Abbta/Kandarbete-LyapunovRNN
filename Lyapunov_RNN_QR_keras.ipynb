{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jzS_qaJhZZBm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "layers = keras.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for calculating LE"
      ],
      "metadata": {
        "id": "-vkFsAtDZaqg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tT_h6dH6ZZBo"
      },
      "outputs": [],
      "source": [
        "def rnn_jac(Wxh, Whh, ht, xt, phiprime):\n",
        "    \"\"\"\n",
        "    Compute the Jacobian of the RNN with respect to the hidden state ht\n",
        "    :param Wxh: input-to-hidden weight matrix (U)\n",
        "    :param Whh: hidden-to-hidden weight matrix (V)\n",
        "    :param ht: current hidden state\n",
        "    :param xt: current input\n",
        "    :param phiprime: function handle for the derivative of the activation function\n",
        "    :return: Jacobian matrix\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute the Jacobian of the RNN with respect to ht\n",
        "\n",
        "    alpha=Wxh@xt + Whh@ht\n",
        "    J=np.diag(phiprime(alpha))@Whh\n",
        "    return J\n",
        "\n",
        "def calc_LEs(x_batches, h0, RNNlayer, activation_function_prim=lambda x:np.heaviside(x,1), k_LE=1000):\n",
        "    \"\"\"\n",
        "    Calculate the Lyapunov exponents of a batch of sequences using the QR method.\n",
        "    :param x_batches: input sequences (batch_size, T, input_size)\n",
        "    :param h0: initial hidden state (batch_size, hidden_size)\n",
        "    :param RNNlayer: RNN layer object (e.g., tf.keras.layers.SimpleRNN)\n",
        "    :param activation_function_prim: function handle to derivative of activation function used in the RNN layer\n",
        "    :param k_LE: number of Lyapunov exponents to compute\n",
        "    :return: Lyapunov exponents for each batch (batch_size, k_LE)\n",
        "    \"\"\"\n",
        "    #get dimensions\n",
        "    hidden_size = h0.shape[0]\n",
        "    batch_size, T, input_size = x_batches.shape\n",
        "    L = hidden_size\n",
        "\n",
        "    #get recurrent cell\n",
        "    RNNcell=RNNlayer.cell\n",
        "\n",
        "    # Choose how many exponents to track\n",
        "    k_LE = max(min(L, k_LE), 1)\n",
        "\n",
        "    #save average Lyapunov exponent over the sequence for each batch\n",
        "    lyaps_batches = np.zeros((batch_size, k_LE))\n",
        "    #Loop over input sequence\n",
        "    for batch in range(batch_size):\n",
        "        x=x_batches[batch]\n",
        "        ht=h0\n",
        "        #Initialize Q\n",
        "        Q = tf.eye(L)\n",
        "        #keep track of average lyapunov exponents\n",
        "        cum_lyaps = tf.zeros((k_LE,))\n",
        "\n",
        "        for t in range(T):\n",
        "            #Get next state ht+1 by taking a reccurent step\n",
        "            xt=x[t]\n",
        "            _, ht = RNNcell(xt, ht)\n",
        "\n",
        "            #Get jacobian J\n",
        "            Wxh, Whh, b = rnn_layer.get_weights()\n",
        "            # Transpose to match math-style dimensions\n",
        "            Wxh = Wxh.T  # Now shape (units, input_dim)\n",
        "            Whh = Whh.T  # Now shape (units, units)\n",
        "            J = rnn_jac(Wxh, Whh, ht, xt, activation_function_prim)\n",
        "\n",
        "            #Get the Lyapunov exponents from qr decomposition\n",
        "            Q=Q@J\n",
        "            Q,R=tf.linalg.qr(Q, full_matrices=False)\n",
        "            cum_lyaps += tf.math.log(tf.linalg.diag_part(R[0:k_LE, 0:k_LE]))\n",
        "        lyaps_batches[batch] = cum_lyaps / T\n",
        "    return lyaps_batches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code used to test/show implementation"
      ],
      "metadata": {
        "id": "RkJlXIaIZpSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start out with defining and training a toy model"
      ],
      "metadata": {
        "id": "jSKVdKCHdXJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model():\n",
        "    \"\"\"Define and compile a simple RNN model.\"\"\"\n",
        "    z0 = layers.Input(shape=[None, 1])  # time steps unspecified, 1 feature\n",
        "    z = layers.SimpleRNN(32, activation=\"tanh\")(z0)\n",
        "    z = layers.Dense(32, activation='relu')(z)\n",
        "    z = layers.Dense(16, activation='relu')(z)\n",
        "    z = layers.Dense(1)(z)\n",
        "\n",
        "    model = keras.models.Model(inputs=z0, outputs=z)\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "def train_model(model, X, y, epochs=20, batch_size=10):\n",
        "    \"\"\"Train model with early stopping and LR scheduler.\"\"\"\n",
        "    results = model.fit(\n",
        "        X, y,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_split=0.1,\n",
        "        verbose=1,\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(factor=0.67, patience=3, verbose=1, min_lr=1E-5),\n",
        "            keras.callbacks.EarlyStopping(patience=4, verbose=1)\n",
        "        ]\n",
        "    )\n",
        "    return results\n",
        "\n",
        "# Create some toy data\n",
        "n_samples = 300\n",
        "time_steps = 20\n",
        "X = np.random.rand(n_samples, time_steps, 1)  # [batch, time, features]\n",
        "Y = np.random.rand(n_samples)\n",
        "\n",
        "# Create and train model\n",
        "model = define_model()\n",
        "results = train_model(model, X, Y)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__LaaRB8Zw9s",
        "outputId": "1dc54011-e9e6-4fe1-f0a8-6318c50d6674"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.2049 - val_loss: 0.0819 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0835 - val_loss: 0.0808 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0829 - val_loss: 0.0810 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0726 - val_loss: 0.0808 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0867 - val_loss: 0.0795 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0760 - val_loss: 0.0790 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0813 - val_loss: 0.0800 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0797 - val_loss: 0.0789 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0816 - val_loss: 0.0783 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0742 - val_loss: 0.0798 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0767 - val_loss: 0.0777 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0726 - val_loss: 0.0781 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0828 - val_loss: 0.0856 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m24/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0806\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006700000318232924.\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0803 - val_loss: 0.0822 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0771 - val_loss: 0.0783 - learning_rate: 6.7000e-04\n",
            "Epoch 15: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can calulate the LEs of the model"
      ],
      "metadata": {
        "id": "2gOrugH_dcKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create some batches of input data and initial hidden states\n",
        "batch_size = 10   # number of sequences\n",
        "T = 20            # length of each sequence\n",
        "input_dim = 1     # each x is a scalar\n",
        "hidden_dim = 32   # size of hidden state\n",
        "\n",
        "X = np.random.rand(batch_size, T, input_dim)\n",
        "H0 = np.random.rand(batch_size, hidden_dim)\n",
        "\n",
        "#Get the rnn layer of the model\n",
        "rnn_layer=model.layers[1]\n",
        "\n",
        "#Define the derivative of the activation function used\n",
        "tanh_prim=lambda x: 1-np.pow(np.tanh(x), 2)\n",
        "\n",
        "#calculate the LEs\n",
        "number_exponents=20\n",
        "LEs=calc_LEs(X,H0, rnn_layer, tanh_prim, number_exponents)\n",
        "print(LEs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "XzVjWE4EdVfY",
        "outputId": "db3f1ab3-fbfc-443d-c757-b48e6f998690"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 1) (32, 32) (10, 32) (1,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [32,32], In[1]: [10,32] [Op:MatMul] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-edb11e97ab3b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#calculate the LEs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnumber_exponents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mLEs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_LEs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtanh_prim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_exponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLEs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-8c531c6f1eb7>\u001b[0m in \u001b[0;36mcalc_LEs\u001b[0;34m(x_batches, h0, RNNlayer, activation_function_prim, k_LE)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mWxh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWxh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# Now shape (units, input_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mWhh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# Now shape (units, units)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_jac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWxh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function_prim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m#Get the Lyapunov exponents from qr decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-8c531c6f1eb7>\u001b[0m in \u001b[0;36mrnn_jac\u001b[0;34m(Wxh, Whh, ht, xt, phiprime)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Compute the Jacobian of the RNN with respect to ht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWxh\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mxt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mWhh\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mJ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphiprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mWhh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6001\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6002\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [32,32], In[1]: [10,32] [Op:MatMul] name: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}